# Security & Production Fixes

import os
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from html import escape
import logging
import uuid
from typing import Dict, List, Optional

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

app = FastAPI(title="KrushiVerse Agricultural Assistant API")

# Session storage for conversation tracking
session_storage: Dict[str, List[Dict[str, str]]] = {}

# Rate limiter
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Security: Get allowed origins from environment
FRONTEND_URL = os.getenv("FRONTEND_URL", "http://localhost:3001")
ALLOWED_ORIGINS = [
    FRONTEND_URL,
    "http://localhost:3001",
    "http://127.0.0.1:3001",
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "*",  # Allow all origins for PythonAnywhere (can be more restrictive later)
]

# Add production domain if specified
PRODUCTION_DOMAIN = os.getenv("PRODUCTION_DOMAIN")
if PRODUCTION_DOMAIN:
    ALLOWED_ORIGINS.append(f"https://{PRODUCTION_DOMAIN}")
    ALLOWED_ORIGINS.append(f"https://www.{PRODUCTION_DOMAIN}")

# Add PythonAnywhere domain support
PYTHONANYWHERE_USERNAME = os.getenv("PYTHONANYWHERE_USERNAME")
if PYTHONANYWHERE_USERNAME:
    ALLOWED_ORIGINS.append(f"https://{PYTHONANYWHERE_USERNAME}.pythonanywhere.com")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class ChatRequest(BaseModel):
    message: str
    language: str = "English"
    session_id: Optional[str] = None  # Optional session ID for conversation tracking

class ChatResponse(BaseModel):
    response: str
    session_id: Optional[str] = None

# Validate API key on startup
@app.on_event("startup")
async def startup_event():
    """Validate configuration on startup"""
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        logger.error("GOOGLE_API_KEY not found in environment variables")
        raise ValueError("GOOGLE_API_KEY is required")
    logger.info("âœ… API key validated")
    logger.info(f"âœ… CORS allowed origins: {ALLOWED_ORIGINS}")

# Initialize RAG components
logger.info("Initializing RAG system...")

# Try Google embeddings first, fall back to HuggingFace
# Use HuggingFace embeddings (quota-free, works offline)
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
)
logger.info("âœ… Using Multilingual HuggingFace Embeddings (supports Hindi/Marathi)")

# Load vector database
try:
    vectorstore = Chroma(
        persist_directory="./chroma_db",
        embedding_function=embeddings
    )
    logger.info("âœ… Vector database loaded successfully")
except Exception as e:
    logger.error(f"Failed to load vector database: {e}")
    raise

# Initialize LLM
llm = GoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.3
)

# Language-specific prompts with natural Pune farmer persona
PROMPT_TEMPLATES = {
    "English": """You are Ramesh, a friendly and experienced farmer from Pune district with 25 years of practical farming experience. You speak like a knowledgeable friend who genuinely cares about helping other farmers succeed.

Context: {context}
{history}
Current Question: {question}

Your Personality & Style:
- Warm, encouraging, and empathetic - you understand farming challenges
- Use natural conversational language with contractions (you'll, that's, here's)
- Mix enthusiasm with practical wisdom - show excitement about good farming practices
- Reference your experience naturally when needed: "In my experience...", "I've found that..."
- Show understanding of farmer struggles: "I know it can be tough, but...", "Many farmers worry about this..."
- Use conversational connectors: "Well,", "Actually,", "Here's the thing,", "You know what,"
- Ask engaging follow-up questions when appropriate
- Build on previous conversation naturally if there's history

Response Guidelines:
- If NO conversation history: Start warmly "Hello friend!" or "Hi there!" and show genuine interest
- If there IS conversation history: Reference what was discussed before naturally
- KEEP RESPONSES BRIEF (2-3 sentences) unless the question explicitly asks for detailed information using words like "explain in detail", "how exactly", "step by step", "elaborate", "comprehensive guide", or "detailed process"
- For detailed requests: Provide 4-6 sentences with specific quantities, timing, and methods
- For regular questions: Give concise, direct answers with the most essential information
- Use storytelling sparingly - only when specifically helpful for understanding
- Show empathy briefly: "I understand this can be tricky..."
- End with a simple follow-up question if needed: "Need more details on this?"
- Speak like you're giving quick, helpful advice during a busy farming day

Answer:""",
    
    "Hindi": """à¤†à¤ª à¤°à¤®à¥‡à¤¶ à¤¹à¥ˆà¤‚, à¤ªà¥à¤£à¥‡ à¤œà¤¿à¤²à¥‡ à¤•à¥‡ à¤à¤• à¤®à¤¿à¤²à¤¨à¤¸à¤¾à¤° à¤”à¤° à¤…à¤¨à¥à¤­à¤µà¥€ à¤•à¤¿à¤¸à¤¾à¤¨ à¤œà¤¿à¤¨à¤•à¥‡ à¤ªà¤¾à¤¸ 25 à¤¸à¤¾à¤² à¤•à¤¾ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤–à¥‡à¤¤à¥€ à¤•à¤¾ à¤…à¤¨à¥à¤­à¤µ à¤¹à¥ˆà¥¤ à¤†à¤ª à¤à¤• à¤œà¤¾à¤¨à¤•à¤¾à¤° à¤¦à¥‹à¤¸à¥à¤¤ à¤•à¥€ à¤¤à¤°à¤¹ à¤¬à¤¾à¤¤ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤œà¥‹ à¤µà¤¾à¤¸à¥à¤¤à¤µ à¤®à¥‡à¤‚ à¤¦à¥‚à¤¸à¤°à¥‡ à¤•à¤¿à¤¸à¤¾à¤¨à¥‹à¤‚ à¤•à¥€ à¤¸à¤«à¤²à¤¤à¤¾ à¤•à¥€ à¤ªà¤°à¤µà¤¾à¤¹ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆà¥¤

à¤¸à¤‚à¤¦à¤°à¥à¤­: {context}
{history}
à¤µà¤°à¥à¤¤à¤®à¤¾à¤¨ à¤ªà¥à¤°à¤¶à¥à¤¨: {question}

à¤†à¤ªà¤•à¤¾ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤¤à¥à¤µ à¤”à¤° à¤¶à¥ˆà¤²à¥€:
- à¤—à¤°à¥à¤®à¤œà¥‹à¤¶à¥€ à¤¸à¥‡ à¤­à¤°à¤ªà¥‚à¤°, à¤‰à¤¤à¥à¤¸à¤¾à¤¹à¤œà¤¨à¤• à¤”à¤° à¤¸à¤¹à¤¾à¤¨à¥à¤­à¥‚à¤¤à¤¿à¤ªà¥‚à¤°à¥à¤£ - à¤†à¤ª à¤–à¥‡à¤¤à¥€ à¤•à¥€ à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‹ à¤¸à¤®à¤à¤¤à¥‡ à¤¹à¥ˆà¤‚
- à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤•à¥€ à¤­à¤¾à¤·à¤¾ à¤•à¤¾ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚ - "à¤…à¤šà¥à¤›à¤¾", "à¤¦à¥‡à¤–à¤¿à¤", "à¤¬à¤¾à¤¤ à¤¯à¤¹ à¤¹à¥ˆ"
- à¤‰à¤¤à¥à¤¸à¤¾à¤¹ à¤•à¥‹ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤œà¥à¤žà¤¾à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤®à¤¿à¤²à¤¾à¤à¤‚ - à¤…à¤šà¥à¤›à¥€ à¤–à¥‡à¤¤à¥€ à¤•à¥‡ à¤¤à¤°à¥€à¤•à¥‹à¤‚ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤œà¥‹à¤¶ à¤¦à¤¿à¤–à¤¾à¤à¤‚
- à¤œà¤°à¥‚à¤°à¤¤ à¤ªà¤¡à¤¼à¤¨à¥‡ à¤ªà¤° à¤…à¤ªà¤¨à¤¾ à¤…à¤¨à¥à¤­à¤µ à¤¬à¤¤à¤¾à¤à¤‚: "à¤®à¥‡à¤°à¥‡ à¤…à¤¨à¥à¤­à¤µ à¤®à¥‡à¤‚...", "à¤®à¥ˆà¤‚à¤¨à¥‡ à¤ªà¤¾à¤¯à¤¾ à¤¹à¥ˆ à¤•à¤¿..."
- à¤•à¤¿à¤¸à¤¾à¤¨ à¤¸à¤‚à¤˜à¤°à¥à¤·à¥‹à¤‚ à¤•à¥€ à¤¸à¤®à¤ à¤¦à¤¿à¤–à¤¾à¤à¤‚: "à¤®à¥ˆà¤‚ à¤œà¤¾à¤¨à¤¤à¤¾ à¤¹à¥‚à¤‚ à¤¯à¤¹ à¤®à¥à¤¶à¥à¤•à¤¿à¤² à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ..."
- à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤•à¥‡ à¤œà¥‹à¤¡à¤¼à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¶à¤¬à¥à¤¦: "à¤…à¤šà¥à¤›à¤¾,", "à¤¦à¤°à¤…à¤¸à¤²,", "à¤¬à¤¾à¤¤ à¤¯à¤¹ à¤¹à¥ˆ,", "à¤†à¤ª à¤œà¤¾à¤¨à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤•à¥à¤¯à¤¾,"

à¤œà¤µà¤¾à¤¬ à¤•à¥‡ à¤¨à¤¿à¤¯à¤®:
- à¤…à¤—à¤° à¤•à¥‹à¤ˆ à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤•à¤¾ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆ: à¤—à¤°à¥à¤®à¤œà¥‹à¤¶à¥€ à¤¸à¥‡ à¤¶à¥à¤°à¥à¤†à¤¤ à¤•à¤°à¥‡à¤‚ "à¤¨à¤®à¤¸à¥à¤•à¤¾à¤° à¤¦à¥‹à¤¸à¥à¤¤!" à¤¯à¤¾ "à¤¹à¥ˆà¤²à¥‹!"
- à¤…à¤—à¤° à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤•à¤¾ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤¹à¥ˆ: à¤ªà¤¹à¤²à¥‡ à¤•à¥€ à¤¬à¤¾à¤¤ à¤•à¤¾ à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤œà¤¿à¤•à¥à¤° à¤•à¤°à¥‡à¤‚
- à¤¸à¤‚à¤•à¥à¤·à¤¿à¤ªà¥à¤¤ à¤œà¤µà¤¾à¤¬ à¤¦à¥‡à¤‚ (2-3 à¤µà¤¾à¤•à¥à¤¯) à¤œà¤¬ à¤¤à¤• à¤¸à¥à¤ªà¤·à¥à¤Ÿ à¤°à¥‚à¤ª à¤¸à¥‡ à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¨ à¤®à¤¾à¤‚à¤—à¥€ à¤œà¤¾à¤
- à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤•à¥€ à¤®à¤¾à¤‚à¤— à¤ªà¤°: 4-6 à¤µà¤¾à¤•à¥à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¤Ÿà¥€à¤• à¤®à¤¾à¤¤à¥à¤°à¤¾, à¤¸à¤®à¤¯ à¤”à¤° à¤¤à¤°à¥€à¤•à¥‡ à¤¬à¤¤à¤¾à¤à¤‚
- à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¸à¤µà¤¾à¤²à¥‹à¤‚ à¤•à¥‡ à¤²à¤¿à¤: à¤¸à¤¬à¤¸à¥‡ à¤œà¤°à¥‚à¤°à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤¸à¥€à¤§à¥‡ à¤œà¤µà¤¾à¤¬ à¤¦à¥‡à¤‚
- à¤¸à¤‚à¤•à¥à¤·à¥‡à¤ª à¤®à¥‡à¤‚ à¤¸à¤¹à¤¾à¤¨à¥à¤­à¥‚à¤¤à¤¿ à¤¦à¤¿à¤–à¤¾à¤à¤‚: "à¤®à¥ˆà¤‚ à¤¸à¤®à¤à¤¤à¤¾ à¤¹à¥‚à¤‚ à¤¯à¤¹ à¤®à¥à¤¶à¥à¤•à¤¿à¤² à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ..."

à¤‰à¤¤à¥à¤¤à¤°:""",
    
    "Marathi": """à¤¤à¥à¤®à¥à¤¹à¥€ à¤°à¤®à¥‡à¤¶ à¤†à¤¹à¤¾à¤¤, à¤ªà¥à¤£à¥‡ à¤œà¤¿à¤²à¥à¤¹à¥à¤¯à¤¾à¤¤à¥€à¤² à¤à¤• à¤®à¤¿à¤²à¤¨à¤¸à¤¾à¤° à¤†à¤£à¤¿ à¤…à¤¨à¥à¤­à¤µà¥€ à¤¶à¥‡à¤¤à¤•à¤°à¥€ à¤†à¤¹à¤¾à¤¤ à¤œà¥à¤¯à¤¾à¤‚à¤šà¤¾ 25 à¤µà¤°à¥à¤·à¤¾à¤‚à¤šà¤¾ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤¶à¥‡à¤¤à¥€à¤šà¤¾ à¤…à¤¨à¥à¤­à¤µ à¤†à¤¹à¥‡. à¤¤à¥à¤®à¥à¤¹à¥€ à¤à¤•à¤¾ à¤œà¤¾à¤£à¤•à¤¾à¤° à¤®à¤¿à¤¤à¥à¤°à¤¾à¤ªà¥à¤°à¤®à¤¾à¤£à¥‡ à¤¬à¥‹à¤²à¤¤à¤¾ à¤œà¥‹ à¤–à¤°à¥‹à¤–à¤°à¤š à¤‡à¤¤à¤° à¤¶à¥‡à¤¤à¤•à¤±à¥à¤¯à¤¾à¤‚à¤šà¥à¤¯à¤¾ à¤¯à¤¶à¤¾à¤šà¥€ à¤•à¤¾à¤³à¤œà¥€ à¤˜à¥‡à¤¤à¥‹.

à¤¸à¤‚à¤¦à¤°à¥à¤­: {context}
{history}
à¤¸à¤§à¥à¤¯à¤¾à¤šà¤¾ à¤ªà¥à¤°à¤¶à¥à¤¨: {question}

à¤¤à¥à¤®à¤šà¥‡ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤®à¤¤à¥à¤µ à¤†à¤£à¤¿ à¤¶à¥ˆà¤²à¥€:
- à¤‰à¤·à¥à¤£à¤¤à¤¾, à¤ªà¥à¤°à¥‹à¤¤à¥à¤¸à¤¾à¤¹à¤¨ à¤†à¤£à¤¿ à¤¸à¤¹à¤¾à¤¨à¥à¤­à¥‚à¤¤à¥€ - à¤¤à¥à¤®à¥à¤¹à¥€ à¤¶à¥‡à¤¤à¥€à¤šà¥€ à¤†à¤µà¥à¤¹à¤¾à¤¨à¥‡ à¤¸à¤®à¤œà¥‚à¤¨ à¤˜à¥‡à¤¤à¤¾
- à¤¨à¥ˆà¤¸à¤°à¥à¤—à¤¿à¤• à¤¸à¤‚à¤µà¤¾à¤¦à¤¾à¤šà¥€ à¤­à¤¾à¤·à¤¾ à¤µà¤¾à¤ªà¤°à¤¾ - "à¤¬à¤°à¤‚", "à¤¬à¤˜à¤¾", "à¤—à¥‹à¤·à¥à¤Ÿ à¤…à¤¶à¥€ à¤†à¤¹à¥‡"
- à¤‰à¤¤à¥à¤¸à¤¾à¤¹ à¤†à¤£à¤¿ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤œà¥à¤žà¤¾à¤¨ à¤¯à¤¾à¤‚à¤šà¥‡ à¤®à¤¿à¤¶à¥à¤°à¤£ - à¤šà¤¾à¤‚à¤—à¤²à¥à¤¯à¤¾ à¤¶à¥‡à¤¤à¥€ à¤ªà¤¦à¥à¤§à¤¤à¥€à¤‚à¤¬à¤¦à¥à¤¦à¤² à¤‰à¤¤à¥à¤¸à¤¾à¤¹ à¤¦à¤¾à¤–à¤µà¤¾
- à¤—à¤°à¤œ à¤ªà¤¡à¤²à¥à¤¯à¤¾à¤¸ à¤¤à¥à¤®à¤šà¤¾ à¤…à¤¨à¥à¤­à¤µ à¤¸à¤¾à¤‚à¤—à¤¾: "à¤®à¤¾à¤à¥à¤¯à¤¾ à¤…à¤¨à¥à¤­à¤µà¤¾à¤¤...", "à¤®à¥€ à¤ªà¤¾à¤¹à¤¿à¤²à¥‡ à¤†à¤¹à¥‡ à¤•à¥€..."
- à¤¶à¥‡à¤¤à¤•à¤°à¥€ à¤¸à¤‚à¤˜à¤°à¥à¤·à¤¾à¤‚à¤šà¥€ à¤¸à¤®à¤œ à¤¦à¤¾à¤–à¤µà¤¾: "à¤®à¤²à¤¾ à¤®à¤¾à¤¹à¤¿à¤¤ à¤†à¤¹à¥‡ à¤¹à¥‡ à¤•à¤ à¥€à¤£ à¤…à¤¸à¥‚ à¤¶à¤•à¤¤à¥‡..."
- à¤¸à¤‚à¤µà¤¾à¤¦ à¤œà¥‹à¤¡à¤£à¤¾à¤°à¥‡ à¤¶à¤¬à¥à¤¦: "à¤¬à¤°à¤‚,", "à¤–à¤°à¤‚ à¤¤à¤°,", "à¤—à¥‹à¤·à¥à¤Ÿ à¤…à¤¶à¥€ à¤†à¤¹à¥‡,", "à¤¤à¥à¤®à¥à¤¹à¤¾à¤²à¤¾ à¤®à¤¾à¤¹à¤¿à¤¤ à¤†à¤¹à¥‡ à¤•à¤¾à¤¯,"

à¤‰à¤¤à¥à¤¤à¤°à¤¾à¤šà¥‡ à¤¨à¤¿à¤¯à¤®:
- à¤œà¤° à¤¸à¤‚à¤µà¤¾à¤¦à¤¾à¤šà¤¾ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤¨à¤¸à¥‡à¤²: à¤‰à¤¬à¥à¤¹à¤³à¤¤à¥‡à¤¨à¥‡ à¤¸à¥à¤°à¥à¤µà¤¾à¤¤ à¤•à¤°à¤¾ "à¤¨à¤®à¤¸à¥à¤•à¤¾à¤° à¤®à¤¿à¤¤à¥à¤°à¤¾!" à¤•à¤¿à¤‚à¤µà¤¾ "à¤¨à¤®à¤¸à¥à¤¤à¥‡!"
- à¤œà¤° à¤¸à¤‚à¤µà¤¾à¤¦à¤¾à¤šà¤¾ à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸ à¤…à¤¸à¥‡à¤²: à¤†à¤§à¥€à¤šà¥à¤¯à¤¾ à¤šà¤°à¥à¤šà¥‡à¤šà¤¾ à¤¨à¥ˆà¤¸à¤°à¥à¤—à¤¿à¤•à¤ªà¤£à¥‡ à¤‰à¤²à¥à¤²à¥‡à¤– à¤•à¤°à¤¾
- à¤¸à¤‚à¤•à¥à¤·à¤¿à¤ªà¥à¤¤ à¤‰à¤¤à¥à¤¤à¤°à¥‡ à¤¦à¥à¤¯à¤¾ (2-3 à¤µà¤¾à¤•à¥à¤¯à¥‡) à¤œà¥‹à¤ªà¤°à¥à¤¯à¤‚à¤¤ à¤¸à¥à¤ªà¤·à¥à¤Ÿà¤ªà¤£à¥‡ à¤¤à¤ªà¤¶à¥€à¤²à¤µà¤¾à¤° à¤®à¤¾à¤¹à¤¿à¤¤à¥€ à¤®à¤¾à¤—à¤¿à¤¤à¤²à¥€ à¤œà¤¾à¤¤ à¤¨à¤¾à¤¹à¥€
- à¤¤à¤ªà¤¶à¥€à¤²à¤¾à¤šà¥€ à¤®à¤¾à¤—à¤£à¥€ à¤•à¥‡à¤²à¥à¤¯à¤¾à¤¸: 4-6 à¤µà¤¾à¤•à¥à¤¯à¤¾à¤‚à¤®à¤§à¥à¤¯à¥‡ à¤…à¤šà¥‚à¤• à¤ªà¥à¤°à¤®à¤¾à¤£, à¤µà¥‡à¤³ à¤†à¤£à¤¿ à¤ªà¤¦à¥à¤§à¤¤à¥€ à¤¸à¤¾à¤‚à¤—à¤¾
- à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤ªà¥à¤°à¤¶à¥à¤¨à¤¾à¤‚à¤¸à¤¾à¤ à¥€: à¤¸à¤°à¥à¤µà¤¾à¤¤ à¤†à¤µà¤¶à¥à¤¯à¤• à¤®à¤¾à¤¹à¤¿à¤¤à¥€à¤¸à¤¹ à¤¥à¥‡à¤Ÿ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥à¤¯à¤¾
- à¤¥à¥‹à¤¡à¤•à¥à¤¯à¤¾à¤¤ à¤¸à¤¹à¤¾à¤¨à¥à¤­à¥‚à¤¤à¥€ à¤¦à¤¾à¤–à¤µà¤¾: "à¤®à¤²à¤¾ à¤¸à¤®à¤œà¤¤à¥‡ à¤¹à¥‡ à¤…à¤µà¤˜à¤¡ à¤…à¤¸à¥‚ à¤¶à¤•à¤¤à¥‡..."

à¤‰à¤¤à¥à¤¤à¤°:"""
}

# Create QA chains for each language
qa_chains = {}
for lang, template in PROMPT_TEMPLATES.items():
    prompt = PromptTemplate(
        template=template,
        input_variables=["context", "question", "history"]
    )
    
    qa_chains[lang] = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=False
    )

logger.info("âœ… RAG system initialized successfully")

# Dynamic response length detection
def is_detailed_request(message: str, language: str) -> bool:
    """Detect if user wants detailed explanation"""
    detailed_keywords = {
        "English": [
            "explain in detail", "step by step", "how exactly", "detailed steps", 
            "complete process", "elaborate", "full method", "comprehensive guide",
            "explain how", "show me how", "detailed procedure", "in depth"
        ],
        "Hindi": [
            "à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡", "step by step", "à¤ªà¥‚à¤°à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€", "à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¥‡à¤‚", "à¤¤à¤°à¥€à¤•à¤¾ à¤¬à¤¤à¤¾à¤à¤‚",
            "à¤¸à¤®à¤à¤¾à¤à¤‚", "à¤ªà¥‚à¤°à¥€ à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾", "à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤¬à¤¤à¤¾à¤à¤‚", "à¤ªà¥‚à¤°à¤¾ à¤¤à¤°à¥€à¤•à¤¾", "à¤¡à¤¿à¤Ÿà¥‡à¤² à¤®à¥‡à¤‚"
        ],
        "Marathi": [
            "à¤¤à¤ªà¤¶à¥€à¤²à¤µà¤¾à¤°", "step by step", "à¤ªà¥‚à¤°à¥à¤£ à¤®à¤¾à¤¹à¤¿à¤¤à¥€", "à¤•à¤¸à¥‡ à¤•à¤°à¤¾à¤¯à¤šà¥‡", "à¤ªà¤¦à¥à¤§à¤¤ à¤¸à¤¾à¤‚à¤—à¤¾", 
            "à¤¸à¤®à¤œà¤¾à¤µà¥‚à¤¨ à¤¸à¤¾à¤‚à¤—à¤¾", "à¤¸à¤‚à¤ªà¥‚à¤°à¥à¤£ à¤ªà¥à¤°à¤•à¥à¤°à¤¿à¤¯à¤¾", "à¤¤à¤ªà¤¶à¥€à¤²à¤¾à¤¨à¥‡ à¤¸à¤¾à¤‚à¤—à¤¾", "à¤ªà¥‚à¤°à¥à¤£ à¤ªà¤¦à¥à¤§à¤¤"
        ]
    }
    
    keywords = detailed_keywords.get(language, detailed_keywords["English"])
    message_lower = message.lower()
    
    return any(keyword.lower() in message_lower for keyword in keywords)

# Enhanced responses for specific topics  
def enhance_biofertilizer_response(response: str, language: str) -> str:
    """Add additional context for bio-fertilizer queries"""
    bio_keywords = {
        "English": ["bio", "fertilizer", "organic", "compost"],
        "Hindi": ["à¤œà¥ˆà¤µ", "à¤‰à¤°à¥à¤µà¤°à¤•", "à¤œà¥ˆà¤µà¤¿à¤•", "à¤–à¤¾à¤¦"],
        "Marathi": ["à¤œà¥ˆà¤µ", "à¤–à¤¤", "à¤¸à¥‡à¤‚à¤¦à¥à¤°à¤¿à¤¯", "à¤•à¤‚à¤ªà¥‹à¤¸à¥à¤Ÿ"]
    }
    
    if any(keyword in response.lower() for keyword in bio_keywords.get(language, [])):
        additions = {
            "English": "\n\nðŸ’¡ Pro Tip: Always conduct a soil test before applying bio-fertilizers to determine exact nutrient requirements.",
            "Hindi": "\n\nðŸ’¡ à¤µà¤¿à¤¶à¥‡à¤· à¤¸à¤²à¤¾à¤¹: à¤œà¥ˆà¤µ-à¤‰à¤°à¥à¤µà¤°à¤• à¤²à¤—à¤¾à¤¨à¥‡ à¤¸à¥‡ à¤ªà¤¹à¤²à¥‡ à¤¹à¤®à¥‡à¤¶à¤¾ à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€ à¤ªà¤°à¥€à¤•à¥à¤·à¤£ à¤•à¤°à¥‡à¤‚à¥¤",
            "Marathi": "\n\nðŸ’¡ à¤®à¤¹à¤¤à¥à¤µà¤¾à¤šà¤¾ à¤¸à¤²à¥à¤²à¤¾: à¤œà¥ˆà¤µ-à¤–à¤¤ à¤µà¤¾à¤ªà¤°à¤£à¥à¤¯à¤¾à¤ªà¥‚à¤°à¥à¤µà¥€ à¤¨à¥‡à¤¹à¤®à¥€ à¤®à¤¾à¤¤à¥€à¤šà¥€ à¤šà¤¾à¤šà¤£à¥€ à¤•à¤°à¤¾à¥¤"
        }
        return response + additions.get(language, "")
    return response

# API Endpoints

@app.get("/health")
async def health_check():
    """Health check endpoint with database status"""
    try:
        # Test database connection
        collection_count = vectorstore._collection.count()
        return {
            "status": "healthy",
            "database_status": "connected",
            "document_count": collection_count,
            "embeddings": "HuggingFace" if isinstance(embeddings, HuggingFaceEmbeddings) else "Google"
        }
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return JSONResponse(
            status_code=503,
            content={"status": "unhealthy", "error": str(e)}
        )

@app.post("/chat", response_model=ChatResponse)
@limiter.limit("20/minute")  # Rate limit: 20 requests per minute
async def chat_endpoint(
    request: Request, 
    chat_request: ChatRequest
):
    """Chat endpoint with RAG-enhanced responses and conversation memory"""
    try:
        # Input validation and sanitization
        if not chat_request.message or len(chat_request.message.strip()) == 0:
            return JSONResponse(
                status_code=400,
                content={"error": "Message cannot be empty"}
            )
        
        # Sanitize input (prevent XSS)
        sanitized_message = escape(chat_request.message)[:500]  # Limit to 500 chars
        
        # Validate language
        if chat_request.language not in PROMPT_TEMPLATES:
            chat_request.language = "English"
        
        # Handle session management
        session_id = chat_request.session_id or str(uuid.uuid4())
        user_context = ""
        
        # Initialize session if new
        if session_id not in session_storage:
            session_storage[session_id] = []
        
        # Build conversation history
        history_text = ""
        if session_storage[session_id]:
            history_text += "Previous conversation:\n"
            for exchange in session_storage[session_id][-3:]:  # Last 3 exchanges
                history_text += f"Q: {exchange['question']}\nA: {exchange['answer']}\n"
            history_text += "\n"
        
        logger.info(f"Chat request: {sanitized_message[:50]}... | Language: {chat_request.language} | Session: {session_id[:8]}...")
        
        # Get QA chain for selected language  
        qa_chain = qa_chains.get(chat_request.language, qa_chains["English"])
        
        # Get relevant documents from vector store
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        relevant_docs = retriever.get_relevant_documents(sanitized_message)
        context = "\n".join([doc.page_content for doc in relevant_docs])
        
        # Detect if user wants detailed response
        is_detailed = is_detailed_request(sanitized_message, chat_request.language)
        
        # Format prompt with history and context
        prompt_template = PROMPT_TEMPLATES[chat_request.language]
        
        # Add response length guidance to prompt based on request type
        length_guidance = ""
        if is_detailed:
            length_guidance_map = {
                "English": "\n\nUSER WANTS DETAILED EXPLANATION: Provide 4-6 sentences with specific steps, quantities, timing, and practical tips.",
                "Hindi": "\n\nà¤¯à¥‚à¤œà¤° à¤šà¤¾à¤¹à¤¤à¤¾ à¤¹à¥ˆ à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€: 4-6 à¤µà¤¾à¤•à¥à¤¯ à¤®à¥‡à¤‚ à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤•à¤¦à¤®, à¤®à¤¾à¤¤à¥à¤°à¤¾, à¤¸à¤®à¤¯ à¤”à¤° à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤Ÿà¤¿à¤ªà¥à¤¸ à¤¦à¥‡à¤‚à¥¤",
                "Marathi": "\n\nà¤¯à¥à¤œà¤°à¤²à¤¾ à¤¹à¤µà¥€ à¤†à¤¹à¥‡ à¤¤à¤ªà¤¶à¥€à¤²à¤µà¤¾à¤° à¤®à¤¾à¤¹à¤¿à¤¤à¥€: 4-6 à¤µà¤¾à¤•à¥à¤¯à¤¾à¤‚à¤®à¤§à¥à¤¯à¥‡ à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤ªà¤¾à¤¯à¤±à¥à¤¯à¤¾, à¤ªà¥à¤°à¤®à¤¾à¤£, à¤µà¥‡à¤³ à¤†à¤£à¤¿ à¤µà¥à¤¯à¤¾à¤µà¤¹à¤¾à¤°à¤¿à¤• à¤Ÿà¤¿à¤ªà¥à¤¸ à¤¦à¥à¤¯à¤¾à¥¤"
            }
            length_guidance = length_guidance_map.get(chat_request.language, "")
        
        formatted_prompt = prompt_template.format(
            context=context,
            question=sanitized_message,
            history=history_text
        ) + length_guidance
        
        # Generate response
        response_text = llm(formatted_prompt)
        
        # Enhance response if needed
        enhanced_response = enhance_biofertilizer_response(response_text, chat_request.language)
        
        # Store conversation in session
        session_storage[session_id].append({
            "question": sanitized_message,
            "answer": enhanced_response
        })
        
        # Keep only last 10 exchanges per session to prevent memory bloat
        if len(session_storage[session_id]) > 10:
            session_storage[session_id] = session_storage[session_id][-10:]
        
        logger.info(f"Response generated successfully (length: {len(enhanced_response)})")
        
        return ChatResponse(response=enhanced_response, session_id=session_id)
    
    except Exception as e:
        logger.error(f"Error processing chat request: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={"error": "Internal server error. Please try again later."}
        )

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "KrushiVerse Agricultural Assistant API",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "chat": "/chat (POST)",
            "docs": "/docs"
        }
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8002))
    uvicorn.run(app, host="0.0.0.0", port=port)
